HIVE_SITE_CONF_javax_jdo_option_ConnectionURL=jdbc:postgresql://steerdmetastore:5432/metastore
HIVE_SITE_CONF_javax_jdo_option_ConnectionDriverName=org.postgresql.Driver
HIVE_SITE_CONF_javax_jdo_option_ConnectionUserName=hive
HIVE_SITE_CONF_javax_jdo_option_ConnectionPassword=root123
HIVE_SITE_CONF_datanucleus_autoCreateSchema=false
HIVE_SITE_CONF_hive_metastore_uris=thrift://hivemetastore:9083

# Following setting is needed because for creating schemas, hive metastore
# try to create a local file db that is not used after this.
# Even if the file is deleted, it works fine after that. Need to observe more.
#---------------------------------------------------
HIVE_SITE_CONF_hive_metastore_warehouse_dir=/tmp/metastore
#---------------------------------------------------

# following was needed because of an issue while processing the CSV files
# https://community.hortonworks.com/content/supportkb/247055/errorjavalangunsupportedoperationexception-storage.html
# https://stackoverflow.com/questions/54035636/how-to-fix-get-table-schema-from-server-error-in-hive
#---------------------------------------------------
HIVE_SITE_CONF_metastore_storage_schema_reader_impl=org.apache.hadoop.hive.metastore.SerDeStorageSchemaReader
#---------------------------------------------------

# Following are settings needed for GCS
#---------------------------------------------------
# HIVE_SITE_CONF_fs_gs_auth_service_account_email=***
# HIVE_SITE_CONF_fs_gs_auth_service_account_private_key_id=***
# HIVE_SITE_CONF_fs_gs_auth_service_account_private_key=***
# HADOOP_CLASSPATH=/tmp/filedata/gcs-connector-hadoop2-latest.jar:${HADOOP_CLASSPATH}
#---------------------------------------------------
